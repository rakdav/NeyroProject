{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-17T07:53:00.662283Z",
     "start_time": "2025-02-17T07:53:00.648423Z"
    }
   },
   "source": [
    "from keras import Model\n",
    "from keras.src.models import Sequential\n",
    "from keras.api.preprocessing import image\n",
    "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
    "from keras.src.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D\n",
    "from keras import applications\n"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:38.766500Z",
     "start_time": "2025-02-17T08:07:38.752682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "img_width,img_height=150,150\n",
    "train_data_dir=\"datasets/train\"\n",
    "validation_data_dir=\"val\"\n",
    "nb_train_samples=2000\n",
    "nb_validation_samples=800\n",
    "epochs = 5\n",
    "batch_size = 16"
   ],
   "id": "ae93741050a79d0",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:41.333521Z",
     "start_time": "2025-02-17T08:07:40.914325Z"
    }
   },
   "cell_type": "code",
   "source": "base_model=applications.VGG16(weights='imagenet',include_top=False)",
   "id": "a89e349e131ffe1",
   "outputs": [],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:41.865217Z",
     "start_time": "2025-02-17T08:07:41.842289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x=base_model.output\n",
    "x=GlobalAveragePooling2D()(x)\n",
    "x=Dense(1024,activation='relu')(x)\n",
    "predictions=Dense(2,activation='softmax')(x)"
   ],
   "id": "b25514519fdfa2d6",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:43.405766Z",
     "start_time": "2025-02-17T08:07:43.399432Z"
    }
   },
   "cell_type": "code",
   "source": "model=Model(inputs=base_model.input,outputs=predictions)",
   "id": "a54625d933d8cb65",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:44.893142Z",
     "start_time": "2025-02-17T08:07:44.888629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ],
   "id": "9f13009a6e4d7e58",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:46.037630Z",
     "start_time": "2025-02-17T08:07:46.029064Z"
    }
   },
   "cell_type": "code",
   "source": "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])",
   "id": "52e9475e0226470e",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:49.140388Z",
     "start_time": "2025-02-17T08:07:47.389356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255)\n",
    "train_generator=datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "id": "b0a6cbac5e28adc0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:07:50.559604Z",
     "start_time": "2025-02-17T08:07:50.459386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "validation_generator=datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "id": "1ff389e82b2bd17e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3750 images belonging to 2 classes.\n"
     ]
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:22:13.905388Z",
     "start_time": "2025-02-17T08:22:13.871284Z"
    }
   },
   "cell_type": "code",
   "source": "model.fit(train_generator,steps_per_epoch=nb_train_samples,epochs=epochs,validation_data=validation_generator,validation_steps=nb_validation_samples)",
   "id": "bcce5172d12d7063",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The PyDataset has length 0",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[81], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_train_samples\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation_generator\u001B[49m\u001B[43m,\u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnb_validation_samples\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\tensorflow\\pythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m    121\u001B[0m     \u001B[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m--> 122\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    123\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    124\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\tensorflow\\pythonProject1\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:295\u001B[0m, in \u001B[0;36mPyDatasetAdapter.get_tf_dataset\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    290\u001B[0m     batches \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    291\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_standardize_batch(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpy_dataset[i])\n\u001B[0;32m    292\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(num_samples)\n\u001B[0;32m    293\u001B[0m     ]\n\u001B[0;32m    294\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(batches) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 295\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe PyDataset has length 0\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    296\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_signature \u001B[38;5;241m=\u001B[39m data_adapter_utils\u001B[38;5;241m.\u001B[39mget_tensor_spec(batches)\n\u001B[0;32m    298\u001B[0m ds \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataset\u001B[38;5;241m.\u001B[39mfrom_generator(\n\u001B[0;32m    299\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_iterator,\n\u001B[0;32m    300\u001B[0m     output_signature\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_signature,\n\u001B[0;32m    301\u001B[0m )\n",
      "\u001B[1;31mValueError\u001B[0m: The PyDataset has length 0"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-17T08:22:15.460010Z",
     "start_time": "2025-02-17T08:22:15.299809Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Сохраняем\")\n",
    "model_json=model.to_json()\n",
    "json_file=open(\"vgg16_cat_dogs.json\",\"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()\n",
    "model.save_weights(\"vgg16.weights.h5\")\n",
    "print(\"Сохранение сети завершено\")"
   ],
   "id": "4fc318411c9e79cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сохраняем\n",
      "Сохранение сети завершено\n"
     ]
    }
   ],
   "execution_count": 82
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
